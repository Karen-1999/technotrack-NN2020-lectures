# От линейных моделей к нейронным сетям.
### Часть 2: вероятностные основы обобщенных линейных моделей.


#### Материалы для дополнительного изучения по теме лекции:

Глава 2 "Распределения вероятностей" ("Probability Distributions") книги [Бишоп К.М. "Распознавание образов и машинное обучение"](http://www.combook.ru/product/11965388/) ([*Bishop C.* "Pattern Recognition and Machine Learning"](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)) <br />
Особенно можно сконцентрироваться на разделах 2.3 "Нормальное распределение" ("The Gaussian Distributiion") и 2.4 "Экспоненциально семейство распределений" ("The Exponential Family").

В отношении вероятностных основ линейной регрессии можно также обратить внимание на главу 3 "Модели линейной регрессии" ("Linear Model for Regression"), в особенности раздел 3.1 "Модели с линейными базисными функциями" ("Linear Basis Function Models") и раздел 3.3 "Байесовская линейная регрессия" ("Bayesian Linear Regression").