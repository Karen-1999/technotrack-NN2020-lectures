# Обучение сетей прямого распространения.
### Часть 2: Особенности оптимизации функции потерь (продолжение). Вопросы инициализации параметров.

Дополнительные материалы для самостоятельного изучения.

Список методов по “составлению расписания” LR на [paperswithcode](https://paperswithcode.com/): [link](https://paperswithcode.com/methods/category/learning-rate-schedules)

Два больших блог-поста про оптимизацию в Deep Learning: [снова про learning rate](https://www.jeremyjordan.me/nn-learning-rate/), [в целом про оптимизацию](https://ruder.io/deep-learning-optimization-2017/)

Оригинальная [статья про SGD с warm restarts](https://arxiv.org/abs/1608.03983)

[A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation](https://openreview.net/pdf?id=r14EOsCqKX)

Статья про инициализацию параметров с интерактивными визуализациями [обязательно к прочтению](https://www.deeplearning.ai/ai-notes/initialization/)

Оригинальная [статья про инициализацию параметров He](https://arxiv.org/abs/1502.01852)
