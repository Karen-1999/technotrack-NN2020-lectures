# Домашнее задание №4
### Обзор последних исследовательских статей

В этом домашнем задании вам предлагается написать отзыв на одну из статей из списка ниже. Мы осознаем, что вашей квалификации, возможно, недостаточно для написания полноценного отзыва, однако любая попытка будет оцениваться.

В отзыве обычно присутствуют следующие разделы:

- Заголовок, включающий полное название статьи и пояснение, что это отзыв на эту статью.
- Автор отзыва указывается в зависимости от применяемой издательством процедуры рецензирования. Бывает т.н. открытое рецензирование - где указывается автор отзыва. В процедуре слепого рецензирования автор отзыва не указывается. В рамках процедуры двойного слепого рецензирования ни автор отзыва не знает авторов статьи, ни авторы статьи не знают, чей отзыв предлагается им на рассмотрение. **В предлагаемом ДЗ предлагается применять сценарий открытого рецензирования.**
- Аннотация статьи своими словами. Этот раздел может быть воспринят как аналог аннотации (abstract), предложенной автором рецензии. В этой аннотации рецензент кратко излагает свое понимание статьи и основных ее положений.
- Содержательная часть: достижения работы, описанной в статье, и недостатки, замеченные в исследовании или описании исследования. В этом разделе может обсуждаться все, что касается сути исследования. Достоинства и недостатки предложенных методов. Положительные и отрицательные стороны полученных результатов. Особенности интерпретации результатов с точки зрения авторов статьи и с точки зрения рецензента. Следует понимать, что точка зрения авторов может быть сильно отличной от точки зрения рецензента. В задачу рецензента входит попытка войти в положение авторов, оценить их вклад с этой точки зрения, но также и оценить достижения продемонстрированной работы с других точек зрения.
- Обычно в академических рецензиях пишут вывод: (а) либо статья достойна публикации в представленном виде, (б) либо материалу требуются незначительные правки, (в) либо статья не готова к публикации и, по мнению рецензента, требует существенной доработки (исправления методов, исправления дизайна экспериментов и т.д.), (г) либо исследование не имеет шанса на опубликование вследствие обилия ошибок и неточностей. Поскольку все эти статьи уже опубликованы, этот раздел можно опустить. Но вам все же предлагается сформулировать вывод, в котором можно оценить вклад исследования, продемонстрированного в статье, в академическое знание об особенностях искусственных нейронных сетей на фоне текущего состояния науки.

Примеры отзывов можно посмотреть, например, [здесь](https://openreview.net/search?term=neurips2019&group=NeurIPS.cc&content=all&source=forum&sort=cdate%3Adesc)


## Предлагаемые к обзору статьи

| Ссылка на статью | Рецензент |
| ----- | ---- |
| [(Akrout et al., 2019) "Deep Learning without Weight Transport"](http://papers.nips.cc/paper/8383-deep-learning-without-weight-transport) | - |
| [(Bernstein and Sheldon, 2019) "Differentially Private Bayesian Linear Regression"](http://papers.nips.cc/paper/8343-differentially-private-bayesian-linear-regression) | Андрей Щеглов |
| [(Defazio, 2019) "On the Curved Geometry of Accelerated Optimization"](http://papers.nips.cc/paper/8453-on-the-curved-geometry-of-accelerated-optimization) | - |
| [(Defazio and Bottou, 2019) "On the Ineffectiveness of Variance Reduced Optimization for Deep Learning"](http://papers.nips.cc/paper/8452-on-the-ineffectiveness-of-variance-reduced-optimization-for-deep-learning) | - |
| [(Dong and Yang, 2019) "Network Pruning via Transformable Architecture Search"](http://papers.nips.cc/paper/8364-network-pruning-via-transformable-architecture-search) | - |
| [(Gower et al., 2019) "RSN: Randomized Subspace Newton"](http://papers.nips.cc/paper/8351-rsn-randomized-subspace-newton) | - |
| [(Hanin and Rolnick, 2019) "Deep ReLU Networks Have Surprisingly Few Activation Patterns"](http://papers.nips.cc/paper/8328-deep-relu-networks-have-surprisingly-few-activation-patterns) | - |
| [(He et al., 2019) "Control Batch Size and Learning Rate to Generalize Well: Theoretical and Empirical Evidence"](http://papers.nips.cc/paper/8398-control-batch-size-and-learning-rate-to-generalize-well-theoretical-and-empirical-evidence) | Дмитрий Мокеев |
| [(Huang et al., 2019) "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"](http://papers.nips.cc/paper/8305-gpipe-efficient-training-of-giant-neural-networks-using-pipeline-parallelism) | - |
| [(Ioannou et al., 2019) "SySCD: A System-Aware Parallel Coordinate Descent Algorithm"](http://papers.nips.cc/paper/8349-syscd-a-system-aware-parallel-coordinate-descent-algorithm) | - |
| [(Kusumoto et al., 2019) "A Graph Theoretic Framework of Recomputation Algorithms for Memory-Efficient Backpropagation"](http://papers.nips.cc/paper/8400-a-graph-theoretic-framework-of-recomputation-algorithms-for-memory-efficient-backpropagation) | - |
| [(Lamy et al., 2019) "Noise-tolerant fair classification"](http://papers.nips.cc/paper/8322-noise-tolerant-fair-classification) | - |
| [(Li et al., 2019) "Positional Normalization"](http://papers.nips.cc/paper/8440-positional-normalization) | Владислав Радамович |
| [(Li, 2019) "SSRGD: Simple Stochastic Recursive Gradient Descent for Escaping Saddle Points"](http://papers.nips.cc/paper/8431-ssrgd-simple-stochastic-recursive-gradient-descent-for-escaping-saddle-points) | Всеволод Скороходов |
| [(Neverova et al., 2019) "Correlated Uncertainty for Learning Dense Correspondences from Noisy Labels"](http://papers.nips.cc/paper/8378-correlated-uncertainty-for-learning-dense-correspondences-from-noisy-labels) | Арсений Белков |
| [(Nguyen et al., 2019) "First Exit Time Analysis of Stochastic Gradient Descent Under Heavy-Tailed Gradient Noise"](http://papers.nips.cc/paper/8320-first-exit-time-analysis-of-stochastic-gradient-descent-under-heavy-tailed-gradient-noise) | - |
| [(Vladymyrov, 2019) "No Pressure! Addressing the Problem of Local Minima in Manifold Learning Algorithms"](http://papers.nips.cc/paper/8357-no-pressure-addressing-the-problem-of-local-minima-in-manifold-learning-algorithms) | - |
| [(Wu et al., 2019) "Stochastic Shared Embeddings: Data-driven Regularization of Embedding Layers"](http://papers.nips.cc/paper/8298-stochastic-shared-embeddings-data-driven-regularization-of-embedding-layers) | Самир Новрузов |